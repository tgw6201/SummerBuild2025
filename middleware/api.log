2025-06-12 21:58:56,551 - middleware.recipe - INFO - Received request with input: {'user': {'age': 30, 'food_preferences': {'allergies': ['peanuts', 'shellfish'], 'special_diet': 'vegetarian'}, 'calorie_target': 2000}, 'ingredients': [{'food': 'whole wheat flour', 'quantity': 1.5, 'unit': 'cups'}, {'food': 'brown sugar', 'quantity': 0.25, 'unit': 'cup'}, {'food': 'olive oil', 'quantity': 2.0, 'unit': 'tablespoons'}, {'food': 'eggs', 'quantity': 1.0, 'unit': 'count'}, {'food': 'almond milk', 'quantity': 0.75, 'unit': 'cup'}, {'food': 'baking soda', 'quantity': 1.0, 'unit': 'teaspoon'}, {'food': 'blueberries', 'quantity': 1.0, 'unit': 'cup'}]}
2025-06-12 21:58:56,551 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: whole wheat flour
2025-06-12 21:58:56,552 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:58:57,141 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=whole%20wheat%20flour HTTP/1.1" 200 None
2025-06-12 21:58:57,142 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 20080
2025-06-12 21:58:57,142 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:58:57,720 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/20080/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=1.5&unit=cups HTTP/1.1" 200 None
2025-06-12 21:58:57,721 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: brown sugar
2025-06-12 21:58:57,722 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:58:58,322 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=brown%20sugar HTTP/1.1" 200 None
2025-06-12 21:58:58,323 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 19334
2025-06-12 21:58:58,323 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:58:58,896 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/19334/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=0.25&unit=cup HTTP/1.1" 200 None
2025-06-12 21:58:58,897 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: olive oil
2025-06-12 21:58:58,897 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:58:59,482 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=olive%20oil HTTP/1.1" 200 None
2025-06-12 21:58:59,484 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 4053
2025-06-12 21:58:59,486 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:00,035 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/4053/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=2.0&unit=tablespoons HTTP/1.1" 200 None
2025-06-12 21:59:00,036 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: eggs
2025-06-12 21:59:00,037 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:00,621 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=eggs HTTP/1.1" 200 None
2025-06-12 21:59:00,623 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 1123
2025-06-12 21:59:00,626 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:01,254 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/1123/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=1.0&unit=count HTTP/1.1" 200 None
2025-06-12 21:59:01,255 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: almond milk
2025-06-12 21:59:01,256 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:01,944 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=almond%20milk HTTP/1.1" 200 None
2025-06-12 21:59:01,945 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 93607
2025-06-12 21:59:01,946 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:02,512 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/93607/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=0.75&unit=cup HTTP/1.1" 200 None
2025-06-12 21:59:02,513 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: baking soda
2025-06-12 21:59:02,514 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:03,073 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=baking%20soda HTTP/1.1" 200 None
2025-06-12 21:59:03,074 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 18372
2025-06-12 21:59:03,075 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:03,660 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/18372/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=1.0&unit=teaspoon HTTP/1.1" 200 None
2025-06-12 21:59:03,661 - middleware.recipe - DEBUG - Searching Spoonacular for ingredient: blueberries
2025-06-12 21:59:03,661 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:04,209 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/search?apiKey=f9e0ebcacc7d4548838c820f298a1339&query=blueberries HTTP/1.1" 200 None
2025-06-12 21:59:04,210 - middleware.recipe - DEBUG - Fetching nutrition details for ingredient ID: 9050
2025-06-12 21:59:04,210 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.spoonacular.com:443
2025-06-12 21:59:04,755 - urllib3.connectionpool - DEBUG - https://api.spoonacular.com:443 "GET /food/ingredients/9050/information?apiKey=f9e0ebcacc7d4548838c820f298a1339&amount=1.0&unit=cup HTTP/1.1" 200 None
2025-06-12 21:59:04,755 - middleware.recipe - INFO - Total calories: 1180.56, Status: within target
2025-06-12 21:59:04,755 - middleware.recipe - DEBUG - Generating recipe with LangChain
2025-06-12 21:59:04,756 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-84ca772f-cd07-4b04-ac8c-ff4636f030ae', 'json_data': {'messages': [{'content': "Suggest a recipe for a 30-year-old user with these ingredients: 1.5 cups whole wheat flour, 0.25 cup brown sugar, 2.0 tablespoons olive oil, 1.0 count eggs, 0.75 cup almond milk, 1.0 teaspoon baking soda, 1.0 cup blueberries. \n                The user has allergies to peanuts, shellfish, follows a vegetarian diet, and has a daily calorie target of 2000 kcal. \n                Return the recipe in JSON format with 'name', 'ingredients', and 'instructions', ensuring it aligns with the diet and avoids allergens.", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.7}}
2025-06-12 21:59:04,757 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 21:59:04,757 - httpcore.connection - DEBUG - close.started
2025-06-12 21:59:04,758 - httpcore.connection - DEBUG - close.complete
2025-06-12 21:59:04,758 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None
2025-06-12 21:59:04,764 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F8207650F0>
2025-06-12 21:59:04,764 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F81FF9A720> server_hostname='api.openai.com' timeout=None
2025-06-12 21:59:04,774 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x000001F82027E0F0>
2025-06-12 21:59:04,774 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 21:59:04,775 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 21:59:04,775 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 21:59:04,775 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 21:59:04,776 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 21:59:05,400 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 12 Jun 2025 13:59:06 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_36a9bc6b9665833d3dac98006277072d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e9dde8a8b09f6b-SIN'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 21:59:05,400 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-12 21:59:05,401 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 21:59:05,401 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 21:59:05,401 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 21:59:05,401 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 21:59:05,401 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Thu, 12 Jun 2025 13:59:06 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_36a9bc6b9665833d3dac98006277072d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e9dde8a8b09f6b-SIN', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 21:59:05,402 - openai._base_client - DEBUG - request_id: req_36a9bc6b9665833d3dac98006277072d
2025-06-12 21:59:05,402 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1535, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-12 21:59:05,403 - openai._base_client - DEBUG - Retrying due to status code 429
2025-06-12 21:59:05,403 - openai._base_client - DEBUG - 2 retries left
2025-06-12 21:59:05,403 - openai._base_client - INFO - Retrying request to /chat/completions in 0.399303 seconds
2025-06-12 21:59:05,811 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-84ca772f-cd07-4b04-ac8c-ff4636f030ae', 'json_data': {'messages': [{'content': "Suggest a recipe for a 30-year-old user with these ingredients: 1.5 cups whole wheat flour, 0.25 cup brown sugar, 2.0 tablespoons olive oil, 1.0 count eggs, 0.75 cup almond milk, 1.0 teaspoon baking soda, 1.0 cup blueberries. \n                The user has allergies to peanuts, shellfish, follows a vegetarian diet, and has a daily calorie target of 2000 kcal. \n                Return the recipe in JSON format with 'name', 'ingredients', and 'instructions', ensuring it aligns with the diet and avoids allergens.", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.7}}
2025-06-12 21:59:05,812 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 21:59:05,812 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 21:59:05,813 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 21:59:05,813 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 21:59:05,813 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 21:59:05,813 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 21:59:06,070 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 12 Jun 2025 13:59:07 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_14cd71b2fce31bd307d35e5645df7a4f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e9ddef2dac9f6b-SIN'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 21:59:06,071 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-12 21:59:06,071 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 21:59:06,071 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 21:59:06,071 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 21:59:06,071 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 21:59:06,072 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Thu, 12 Jun 2025 13:59:07 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_14cd71b2fce31bd307d35e5645df7a4f', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e9ddef2dac9f6b-SIN', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 21:59:06,072 - openai._base_client - DEBUG - request_id: req_14cd71b2fce31bd307d35e5645df7a4f
2025-06-12 21:59:06,072 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1535, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-12 21:59:06,073 - openai._base_client - DEBUG - Retrying due to status code 429
2025-06-12 21:59:06,073 - openai._base_client - DEBUG - 1 retry left
2025-06-12 21:59:06,073 - openai._base_client - INFO - Retrying request to /chat/completions in 0.900726 seconds
2025-06-12 21:59:06,977 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-84ca772f-cd07-4b04-ac8c-ff4636f030ae', 'json_data': {'messages': [{'content': "Suggest a recipe for a 30-year-old user with these ingredients: 1.5 cups whole wheat flour, 0.25 cup brown sugar, 2.0 tablespoons olive oil, 1.0 count eggs, 0.75 cup almond milk, 1.0 teaspoon baking soda, 1.0 cup blueberries. \n                The user has allergies to peanuts, shellfish, follows a vegetarian diet, and has a daily calorie target of 2000 kcal. \n                Return the recipe in JSON format with 'name', 'ingredients', and 'instructions', ensuring it aligns with the diet and avoids allergens.", 'role': 'user'}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.7}}
2025-06-12 21:59:06,978 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-06-12 21:59:06,978 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-06-12 21:59:06,979 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-06-12 21:59:06,979 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-06-12 21:59:06,979 - httpcore.http11 - DEBUG - send_request_body.complete
2025-06-12 21:59:06,979 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-06-12 21:59:07,590 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Date', b'Thu, 12 Jun 2025 13:59:09 GMT'), (b'Content-Type', b'application/json; charset=utf-8'), (b'Content-Length', b'337'), (b'Connection', b'keep-alive'), (b'vary', b'Origin'), (b'x-request-id', b'req_9c426176150e361243417b78f42a5969'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'94e9ddf67ab19f6b-SIN'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-06-12 21:59:07,590 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 429 Too Many Requests"
2025-06-12 21:59:07,590 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-06-12 21:59:07,590 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-06-12 21:59:07,591 - httpcore.http11 - DEBUG - response_closed.started
2025-06-12 21:59:07,591 - httpcore.http11 - DEBUG - response_closed.complete
2025-06-12 21:59:07,591 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "429 Too Many Requests" Headers({'date': 'Thu, 12 Jun 2025 13:59:09 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '337', 'connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': 'req_9c426176150e361243417b78f42a5969', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '94e9ddf67ab19f6b-SIN', 'alt-svc': 'h3=":443"; ma=86400'})
2025-06-12 21:59:07,591 - openai._base_client - DEBUG - request_id: req_9c426176150e361243417b78f42a5969
2025-06-12 21:59:07,592 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1535, in request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\httpx\_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '429 Too Many Requests' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429
2025-06-12 21:59:07,592 - openai._base_client - DEBUG - Re-raising status error
2025-06-12 21:59:07,593 - middleware.recipe - ERROR - Recipe generation error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\recipe.py", line 154, in analyze_food
    recipe_response = await model.ainvoke(prompt_text)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 394, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 968, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
        prompt_messages, stop=stop, callbacks=callbacks, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 926, in agenerate
    raise exceptions[0]
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1094, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
        messages, stop=stop, run_manager=run_manager, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1199, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
2025-06-12 21:59:07,596 - middleware.recipe - ERROR - Error processing request: 500: Failed to generate recipe: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\recipe.py", line 154, in analyze_food
    recipe_response = await model.ainvoke(prompt_text)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 394, in ainvoke
    llm_result = await self.agenerate_prompt(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 968, in agenerate_prompt
    return await self.agenerate(
           ^^^^^^^^^^^^^^^^^^^^^
        prompt_messages, stop=stop, callbacks=callbacks, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 926, in agenerate
    raise exceptions[0]
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_core\language_models\chat_models.py", line 1094, in _agenerate_with_cache
    result = await self._agenerate(
             ^^^^^^^^^^^^^^^^^^^^^^
        messages, stop=stop, run_manager=run_manager, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\langchain_openai\chat_models\base.py", line 1199, in _agenerate
    response = await self.async_client.create(**payload)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
    ...<45 lines>...
    )
    ^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1748, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\venv\Lib\site-packages\openai\_base_client.py", line 1555, in request
    raise self._make_status_error_from_response(err.response) from None
openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\lohc4\Documents\GitHub\SummerBuild2025\middleware\recipe.py", line 161, in analyze_food
    raise HTTPException(status_code=500, detail=f"Failed to generate recipe: {str(e)}")
fastapi.exceptions.HTTPException: 500: Failed to generate recipe: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}
